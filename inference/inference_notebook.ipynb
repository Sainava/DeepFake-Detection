{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "148cba86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries & paths loaded\n"
     ]
    }
   ],
   "source": [
    "from sys import path\n",
    "path.append(\"../src\") \n",
    "path.append(\"..\")   \n",
    "\n",
    "from train_mixed_model import MixedResNet, eval_transform, DEVICE, BEST_MODEL_PATH as BEST_MIXED_MODEL\n",
    "from train_LSTM import VideoLSTM, HIDDEN_SIZE, NUM_LAYERS, BIDIRECTIONAL, DROPOUT, DEVICE as LSTM_DEVICE\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Libraries & paths loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aaf8623f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20 videos: [('../inference/videos/real/id0_0008.mp4', 'real_id0_0008'), ('../inference/videos/real/id0_0009.mp4', 'real_id0_0009')]...\n"
     ]
    }
   ],
   "source": [
    "# === CONFIG: BATCH LIST ===\n",
    "\n",
    "REAL_DIR = \"../inference/videos/real\"\n",
    "FAKE_DIR = \"../inference/videos/fake\"\n",
    "\n",
    "# Make a list of tuples: (video_path, video_name)\n",
    "video_list = []\n",
    "\n",
    "for v in os.listdir(REAL_DIR):\n",
    "    if v.endswith(\".mp4\"):\n",
    "        video_list.append( (os.path.join(REAL_DIR, v), f\"real_{v.split('.')[0]}\") )\n",
    "\n",
    "for v in os.listdir(FAKE_DIR):\n",
    "    if v.endswith(\".mp4\"):\n",
    "        video_list.append( (os.path.join(FAKE_DIR, v), f\"fake_{v.split('.')[0]}\") )\n",
    "\n",
    "print(f\"Found {len(video_list)} videos: {video_list[:2]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e94db38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folders ready\n"
     ]
    }
   ],
   "source": [
    "# === CONFIG ===\n",
    "VIDEO_PATH = \"../inference/videos/real/id0_0000.mp4\"  # <-- üëà Replace with your test Celeb-DF video\n",
    "VIDEO_NAME = \"real_000\"\n",
    "\n",
    "RGB_DIR = \"../dataset/inference_rgb\"\n",
    "FLOW_DIR = \"../dataset/inference_flow\"\n",
    "FEAT_DIR = \"../features/inference\"\n",
    "\n",
    "os.makedirs(os.path.join(RGB_DIR, VIDEO_NAME), exist_ok=True)\n",
    "os.makedirs(os.path.join(FLOW_DIR, VIDEO_NAME), exist_ok=True)\n",
    "os.makedirs(FEAT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Folders ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d785f0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 469 frames.\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "frame_id = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    out_path = os.path.join(RGB_DIR, VIDEO_NAME, f\"frame_{frame_id:04d}.jpg\")\n",
    "    cv2.imwrite(out_path, frame)\n",
    "    frame_id += 1\n",
    "\n",
    "cap.release()\n",
    "print(f\"Extracted {frame_id} frames.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e124c716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed optical flow: 468 flow images.\n"
     ]
    }
   ],
   "source": [
    "from utils.optical_flow_utils import compute_optical_flow, normalize_flow, save_flow_as_image\n",
    "\n",
    "frames = sorted(os.listdir(os.path.join(RGB_DIR, VIDEO_NAME)))\n",
    "\n",
    "for i in range(len(frames)-1):\n",
    "    f1 = os.path.join(RGB_DIR, VIDEO_NAME, frames[i])\n",
    "    f2 = os.path.join(RGB_DIR, VIDEO_NAME, frames[i+1])\n",
    "\n",
    "    img1 = cv2.imread(f1)\n",
    "    img2 = cv2.imread(f2)\n",
    "\n",
    "    gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    flow = compute_optical_flow(gray1, gray2)\n",
    "    norm_flow = normalize_flow(flow)\n",
    "\n",
    "    out_path = os.path.join(FLOW_DIR, VIDEO_NAME)\n",
    "    os.makedirs(out_path, exist_ok=True)\n",
    "    save_flow_as_image(norm_flow, os.path.join(out_path, f\"flow_{i:04d}.jpg\"))\n",
    "\n",
    "print(f\"Computed optical flow: {len(frames)-1} flow images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3b918a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 468 RGB frames for feature extraction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 468/468 [00:13<00:00, 34.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved features: ../features/inference/real_000.npy shape=(468, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# === Load frozen MixedResNet===\n",
    "BEST_MIXED_MODEL = \"../models/mixed_model/best_mixed_model.pth\"\n",
    "\n",
    "# === Load model ===\n",
    "model = MixedResNet().to(DEVICE)\n",
    "assert os.path.exists(BEST_MIXED_MODEL), f\"Path not found: {BEST_MIXED_MODEL}\"\n",
    "model.load_state_dict(torch.load(BEST_MIXED_MODEL, map_location=DEVICE))\n",
    "model.head = torch.nn.Identity()\n",
    "model.eval()\n",
    "\n",
    "# === Video directories ===\n",
    "rgb_vid_dir = os.path.join(RGB_DIR, VIDEO_NAME)\n",
    "flow_vid_dir = os.path.join(FLOW_DIR, VIDEO_NAME)\n",
    "\n",
    "assert os.path.exists(rgb_vid_dir), f\" RGB folder missing: {rgb_vid_dir}\"\n",
    "assert os.path.exists(flow_vid_dir), f\"Flow folder missing: {flow_vid_dir}\"\n",
    "\n",
    "frames = sorted(os.listdir(rgb_vid_dir))\n",
    "frames = [f for f in frames if f.endswith(\".jpg\")]  # only images\n",
    "frames = frames[:-1]  # drop last\n",
    "\n",
    "print(f\"Found {len(frames)} RGB frames for feature extraction.\")\n",
    "\n",
    "video_feats = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for frame in tqdm(frames, desc=\"Extracting features\"):\n",
    "        rgb_path = os.path.join(rgb_vid_dir, frame)\n",
    "        flow_name = frame.replace(\"frame_\", \"flow_\")\n",
    "        flow_path = os.path.join(flow_vid_dir, flow_name)\n",
    "\n",
    "        if not os.path.exists(flow_path):\n",
    "            print(f\"[WARN] Missing flow frame: {flow_path}\")\n",
    "            continue\n",
    "\n",
    "        rgb = Image.open(rgb_path).convert(\"RGB\")\n",
    "        of  = Image.open(flow_path).convert(\"RGB\")\n",
    "\n",
    "        rgb = eval_transform(rgb).unsqueeze(0).to(DEVICE)\n",
    "        of  = eval_transform(of).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "        feat = model(rgb, of).squeeze().cpu().numpy()\n",
    "        video_feats.append(feat)\n",
    "\n",
    "# === Stack & save ===\n",
    "if video_feats:\n",
    "    feats_array = np.stack(video_feats)  # (T, 1024)\n",
    "    feat_file = os.path.join(FEAT_DIR, f\"{VIDEO_NAME}.npy\")\n",
    "    np.save(feat_file, feats_array)\n",
    "    print(f\"‚úÖ Saved features: {feat_file} shape={feats_array.shape}\")\n",
    "else:\n",
    "    print(\"No features extracted. Check your frames.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01895d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Final prediction: REAL\n",
      "Confidence: Real=0.6878, Fake=0.3122\n"
     ]
    }
   ],
   "source": [
    "# === Load trained LSTM ===\n",
    "lstm_path = \"../models/lstm_model/best_lstm.pth\"\n",
    "\n",
    "# same settings as training\n",
    "lstm_model = VideoLSTM(\n",
    "    input_size=1024,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    bidirectional=BIDIRECTIONAL,\n",
    "    dropout=DROPOUT\n",
    ").to(LSTM_DEVICE)\n",
    "\n",
    "lstm_model.load_state_dict(torch.load(lstm_path, map_location=LSTM_DEVICE))\n",
    "lstm_model.eval()\n",
    "\n",
    "features = np.load(feat_file)\n",
    "features = torch.from_numpy(features).unsqueeze(0).float().to(LSTM_DEVICE)  # (1,T,1024)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = lstm_model(features)\n",
    "    probs = torch.softmax(output, dim=1).cpu().numpy().squeeze()\n",
    "\n",
    "    pred = np.argmax(probs)\n",
    "    label = \"REAL\" if pred == 0 else \"FAKE\"\n",
    "\n",
    "print(f\"\\n‚úÖ Final prediction: {label}\")\n",
    "print(f\"Confidence: Real={probs[0]:.4f}, Fake={probs[1]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "70c83882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing real_id0_0008 ===\n",
      "  Frames extracted: 464\n",
      "  Optical flow computed: 463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 463/463 [00:13<00:00, 35.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Final: real_id0_0008 => FAKE | Real=0.0004, Fake=0.9996\n",
      "\n",
      "=== Processing real_id0_0009 ===\n",
      "  Frames extracted: 520\n",
      "  Optical flow computed: 519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 519/519 [00:15<00:00, 34.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Final: real_id0_0009 => REAL | Real=0.9710, Fake=0.0290\n",
      "\n",
      "=== Processing real_id0_0002 ===\n",
      "  Frames extracted: 350\n",
      "  Optical flow computed: 349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 349/349 [00:09<00:00, 35.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Final: real_id0_0002 => REAL | Real=0.9925, Fake=0.0075\n",
      "\n",
      "=== Processing real_id0_0003 ===\n",
      "  Frames extracted: 529\n",
      "  Optical flow computed: 528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 528/528 [00:14<00:00, 37.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Final: real_id0_0003 => REAL | Real=0.9868, Fake=0.0132\n",
      "\n",
      "=== Processing real_id0_0001 ===\n",
      "  Frames extracted: 303\n",
      "  Optical flow computed: 302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 302/302 [00:08<00:00, 37.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Final: real_id0_0001 => REAL | Real=0.9894, Fake=0.0106\n",
      "\n",
      "=== Processing real_id0_0000 ===\n",
      "  Frames extracted: 469\n",
      "  Optical flow computed: 468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 468/468 [00:13<00:00, 35.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Final: real_id0_0000 => REAL | Real=0.6878, Fake=0.3122\n",
      "\n",
      "=== Processing real_id0_0004 ===\n",
      "  Frames extracted: 326\n",
      "  Optical flow computed: 325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 325/325 [00:08<00:00, 36.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Final: real_id0_0004 => FAKE | Real=0.1399, Fake=0.8601\n",
      "\n",
      "=== Processing real_id0_0005 ===\n",
      "  Frames extracted: 459\n",
      "  Optical flow computed: 458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 458/458 [00:12<00:00, 37.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Final: real_id0_0005 => REAL | Real=0.6772, Fake=0.3228\n",
      "\n",
      "=== Processing real_id0_0007 ===\n",
      "  Frames extracted: 479\n",
      "  Optical flow computed: 478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 478/478 [00:13<00:00, 35.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Final: real_id0_0007 => REAL | Real=0.5152, Fake=0.4848\n",
      "\n",
      "=== Processing real_id0_0006 ===\n",
      "  Frames extracted: 534\n",
      "  Optical flow computed: 533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 533/533 [00:14<00:00, 35.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Final: real_id0_0006 => FAKE | Real=0.0594, Fake=0.9406\n",
      "\n",
      "=== Processing fake_id0_id16_0008 ===\n",
      "  Frames extracted: 464\n",
      "  Optical flow computed: 463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 463/463 [00:12<00:00, 35.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Final: fake_id0_id16_0008 => FAKE | Real=0.0005, Fake=0.9995\n",
      "\n",
      "=== Processing fake_id0_id16_0009 ===\n",
      "  Frames extracted: 520\n",
      "  Optical flow computed: 519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 519/519 [00:14<00:00, 36.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Final: fake_id0_id16_0009 => REAL | Real=0.6910, Fake=0.3090\n",
      "\n",
      "=== Processing fake_id0_id16_0001 ===\n",
      "  Frames extracted: 303\n",
      "  Optical flow computed: 302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 302/302 [00:08<00:00, 35.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Final: fake_id0_id16_0001 => FAKE | Real=0.1392, Fake=0.8608\n",
      "\n",
      "=== Processing fake_id0_id16_0000 ===\n",
      "  Frames extracted: 469\n",
      "  Optical flow computed: 468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 468/468 [00:12<00:00, 37.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Final: fake_id0_id16_0000 => FAKE | Real=0.0448, Fake=0.9552\n",
      "\n",
      "=== Processing fake_id0_id16_0002 ===\n",
      "  Frames extracted: 350\n",
      "  Optical flow computed: 349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 349/349 [00:09<00:00, 36.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Final: fake_id0_id16_0002 => FAKE | Real=0.0064, Fake=0.9936\n",
      "\n",
      "=== Processing fake_id0_id16_0003 ===\n",
      "  Frames extracted: 529\n",
      "  Optical flow computed: 528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 528/528 [00:13<00:00, 38.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Final: fake_id0_id16_0003 => FAKE | Real=0.0042, Fake=0.9958\n",
      "\n",
      "=== Processing fake_id0_id16_0007 ===\n",
      "  Frames extracted: 479\n",
      "  Optical flow computed: 478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 478/478 [00:13<00:00, 36.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Final: fake_id0_id16_0007 => FAKE | Real=0.0404, Fake=0.9596\n",
      "\n",
      "=== Processing fake_id0_id16_0006 ===\n",
      "  Frames extracted: 534\n",
      "  Optical flow computed: 533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 533/533 [00:14<00:00, 35.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Final: fake_id0_id16_0006 => FAKE | Real=0.0007, Fake=0.9993\n",
      "\n",
      "=== Processing fake_id0_id16_0004 ===\n",
      "  Frames extracted: 326\n",
      "  Optical flow computed: 325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 325/325 [00:09<00:00, 35.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Final: fake_id0_id16_0004 => FAKE | Real=0.0365, Fake=0.9635\n",
      "\n",
      "=== Processing fake_id0_id16_0005 ===\n",
      "  Frames extracted: 459\n",
      "  Optical flow computed: 458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 458/458 [00:12<00:00, 38.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Final: fake_id0_id16_0005 => FAKE | Real=0.0373, Fake=0.9627\n"
     ]
    }
   ],
   "source": [
    "# === FULL BATCH INFERENCE ===\n",
    "\n",
    "for VIDEO_PATH, VIDEO_NAME in video_list:\n",
    "    print(f\"\\n=== Processing {VIDEO_NAME} ===\")\n",
    "\n",
    "    # 1Ô∏è‚É£ Create folders\n",
    "    os.makedirs(os.path.join(RGB_DIR, VIDEO_NAME), exist_ok=True)\n",
    "    os.makedirs(os.path.join(FLOW_DIR, VIDEO_NAME), exist_ok=True)\n",
    "\n",
    "    # 2Ô∏è‚É£ Extract frames\n",
    "    cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "    frame_id = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        out_path = os.path.join(RGB_DIR, VIDEO_NAME, f\"frame_{frame_id:04d}.jpg\")\n",
    "        cv2.imwrite(out_path, frame)\n",
    "        frame_id += 1\n",
    "    cap.release()\n",
    "    print(f\"  Frames extracted: {frame_id}\")\n",
    "\n",
    "    # 3Ô∏è‚É£ Compute optical flow\n",
    "    from utils.optical_flow_utils import compute_optical_flow, normalize_flow, save_flow_as_image\n",
    "\n",
    "    frames = sorted(os.listdir(os.path.join(RGB_DIR, VIDEO_NAME)))\n",
    "    for i in range(len(frames) - 1):\n",
    "        f1 = os.path.join(RGB_DIR, VIDEO_NAME, frames[i])\n",
    "        f2 = os.path.join(RGB_DIR, VIDEO_NAME, frames[i + 1])\n",
    "\n",
    "        img1 = cv2.imread(f1)\n",
    "        img2 = cv2.imread(f2)\n",
    "        gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "        gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "        flow = compute_optical_flow(gray1, gray2)\n",
    "        norm_flow = normalize_flow(flow)\n",
    "        out_flow_dir = os.path.join(FLOW_DIR, VIDEO_NAME)\n",
    "        os.makedirs(out_flow_dir, exist_ok=True)\n",
    "        save_flow_as_image(norm_flow, os.path.join(out_flow_dir, f\"flow_{i:04d}.jpg\"))\n",
    "    print(f\"  Optical flow computed: {len(frames) - 1}\")\n",
    "\n",
    "    # 4Ô∏è‚É£ Extract features\n",
    "    rgb_vid_dir = os.path.join(RGB_DIR, VIDEO_NAME)\n",
    "    flow_vid_dir = os.path.join(FLOW_DIR, VIDEO_NAME)\n",
    "    frames = sorted(os.listdir(rgb_vid_dir))\n",
    "    frames = [f for f in frames if f.endswith(\".jpg\")][:-1]\n",
    "\n",
    "    video_feats = []\n",
    "    with torch.no_grad():\n",
    "        for frame in tqdm(frames, desc=\"Extracting features\"):\n",
    "            rgb_path = os.path.join(rgb_vid_dir, frame)\n",
    "            flow_name = frame.replace(\"frame_\", \"flow_\")\n",
    "            flow_path = os.path.join(flow_vid_dir, flow_name)\n",
    "            if not os.path.exists(flow_path):\n",
    "                continue\n",
    "            rgb = Image.open(rgb_path).convert(\"RGB\")\n",
    "            of = Image.open(flow_path).convert(\"RGB\")\n",
    "            rgb = eval_transform(rgb).unsqueeze(0).to(DEVICE)\n",
    "            of = eval_transform(of).unsqueeze(0).to(DEVICE)\n",
    "            feat = model(rgb, of).squeeze().cpu().numpy()\n",
    "            video_feats.append(feat)\n",
    "\n",
    "    if not video_feats:\n",
    "        print(\"No features extracted!\")\n",
    "        continue\n",
    "\n",
    "    feats_array = np.stack(video_feats)\n",
    "    feat_file = os.path.join(FEAT_DIR, f\"{VIDEO_NAME}.npy\")\n",
    "    np.save(feat_file, feats_array)\n",
    "\n",
    "    # 5Ô∏è‚É£ Predict with LSTM\n",
    "    features = torch.from_numpy(feats_array).unsqueeze(0).float().to(LSTM_DEVICE)\n",
    "    with torch.no_grad():\n",
    "        output = lstm_model(features)\n",
    "        probs = torch.softmax(output, dim=1).cpu().numpy().squeeze()\n",
    "        pred = np.argmax(probs)\n",
    "        label = \"REAL\" if pred == 0 else \"FAKE\"\n",
    "        print(f\"  ‚úÖ Final: {VIDEO_NAME} => {label} | Real={probs[0]:.4f}, Fake={probs[1]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd8221d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      " [[7 3]\n",
      " [1 9]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        REAL       0.88      0.70      0.78        10\n",
      "        FAKE       0.75      0.90      0.82        10\n",
      "\n",
      "    accuracy                           0.80        20\n",
      "   macro avg       0.81      0.80      0.80        20\n",
      "weighted avg       0.81      0.80      0.80        20\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === FULL BATCH INFERENCE ===\n",
    "# Store true and predicted labels\n",
    "true_labels = []\n",
    "pred_labels = []\n",
    "\n",
    "for VIDEO_PATH, VIDEO_NAME in video_list:\n",
    "    # Ground truth from filename\n",
    "    true = 0 if VIDEO_NAME.startswith(\"real_\") else 1\n",
    "    true_labels.append(true)\n",
    "\n",
    "    # Load prediction\n",
    "    feat_file = os.path.join(FEAT_DIR, f\"{VIDEO_NAME}.npy\")\n",
    "    if not os.path.exists(feat_file):\n",
    "        print(f\"[WARN] Missing features for: {VIDEO_NAME}\")\n",
    "        pred_labels.append(-1)\n",
    "        continue\n",
    "\n",
    "    feats_array = np.load(feat_file)\n",
    "    features = torch.from_numpy(feats_array).unsqueeze(0).float().to(LSTM_DEVICE)\n",
    "    with torch.no_grad():\n",
    "        output = lstm_model(features)\n",
    "        probs = torch.softmax(output, dim=1).cpu().numpy().squeeze()\n",
    "        pred = np.argmax(probs)\n",
    "        pred_labels.append(pred)\n",
    "\n",
    "# Remove any -1 predictions (missing)\n",
    "pairs = [(t, p) for t, p in zip(true_labels, pred_labels) if p >= 0]\n",
    "true_clean, pred_clean = zip(*pairs)\n",
    "\n",
    "# === 1Ô∏è‚É£ Text confusion matrix ===\n",
    "cm = confusion_matrix(true_clean, pred_clean)\n",
    "print(\"\\nConfusion Matrix:\\n\", cm)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(true_clean, pred_clean, target_names=[\"REAL\", \"FAKE\"]))\n",
    "\n",
    "# === 2Ô∏è‚É£ Plot heatmap ===\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=[\"Pred REAL\", \"Pred FAKE\"],\n",
    "            yticklabels=[\"True REAL\", \"True FAKE\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix Heatmap\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepfake-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
